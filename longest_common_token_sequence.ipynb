{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Longest Common Token Sequence: Update 2025-02-04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "def is_word_char(c, word_char_set=set('abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789')):\n",
    "    return c in word_char_set\n",
    "\n",
    "if __name__=='__main__':\n",
    "    print(is_word_char('c'))\n",
    "    print(is_word_char('-'))\n",
    "    print(is_word_char('#'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([5, 4, 3, 2, 1, 0, 5, 4, 3, 2, 1, 0], [0, 0, 0, 0, 0, None, 6, 6, 6, 6, 6, None], {0: 0, 6: 1})\n"
     ]
    }
   ],
   "source": [
    "def find_tokens(text):\n",
    "    #--- forward cumulutive sum of characters -----------------------\n",
    "    csum = [0] * len(text) # initialize to zeros\n",
    "    for i in range(len(text)-1, -1, -1):\n",
    "        if is_word_char(text[i]):\n",
    "            if i == len(text)-1: # if the very last charcter\n",
    "                csum[i] = 1\n",
    "            else:\n",
    "                csum[i] = csum[i+1] + 1\n",
    "\n",
    "    #--- token connectivity = root ----------------------------------\n",
    "    root = [None] * len(text)\n",
    "    ii, cnt = {}, 0\n",
    "    for i in range(len(text)):\n",
    "        if is_word_char(text[i]):\n",
    "            if i == 0 or not is_word_char(text[i-1]): # if the initial character of each token\n",
    "                i_initial = i\n",
    "                ii[i], cnt = cnt, cnt + 1\n",
    "            root[i] = i_initial\n",
    "\n",
    "    return csum, root, ii\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    print(find_tokens('hello world!'))\n",
    "    # ([5, 4, 3, 2, 1, 0, 5, 4, 3, 2, 1, 0], [0, 0, 0, 0, 0, None, 6, 6, 6, 6, 6, None], {0: 0, 6: 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_consecutive_initials(ii, i_not_set):\n",
    "    conn = [0] * len(ii)\n",
    "    for k,v in ii.items():\n",
    "        if k not in i_not_set:\n",
    "            conn[v] = 1\n",
    "\n",
    "    cnt = 0\n",
    "    for i in range(len(conn)):\n",
    "        if conn[i] > 0 and (i == 0 or conn[i-1] == 0):\n",
    "            cnt += 1\n",
    "\n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compare_text(text1, text2, version='latest', verbose=False): # update: 2024-01-25\n",
    "def compare_text(text1, text2, version='latest', verbose=False): # update: 2025-02-04\n",
    "    if version == '1':\n",
    "        return text1 in text2\n",
    "    elif version == '2':\n",
    "        return re.search('(?:^|[^\\w])%s(?:$|[^\\w])'%re.escape(text1.strip()), text2.strip()) is not None\n",
    "\n",
    "    csum1, root1, ii1 = find_tokens(text1)\n",
    "    csum2, root2, ii2 = find_tokens(text2)\n",
    "    if verbose: \n",
    "        print('text1 =', text1)\n",
    "        print(f'csum1 = {csum1}')\n",
    "        print(f'root1 = {root1}')\n",
    "        print(f'ii1 = {ii1}')\n",
    "        print('\\ntext2 =', text2)\n",
    "        print(f'csum2 = {csum2}')\n",
    "        print(f'root2 = {root2}')\n",
    "        print(f'ii2 = {ii2}')\n",
    "\n",
    "    #--- modified (token-by-token) longest common subsequence algorithm ----------------------------------------------\n",
    "    dp = [[0]*(len(text2)+1) for _ in range(len(text1)+1)] # space complexity: O(len(text1) * len(text2))\n",
    "    graph = {} # pointer to the next matched pair or a pathway to it\n",
    "    max_ij = {} # a set of (i,j) coordinate(s) with the highest dp value, for each token-token pair\n",
    "    for i in range(len(text1)-1, -1, -1): # time complexity: O(len(text1) * len(text2))\n",
    "        for j in range(len(text2)-1, -1, -1):\n",
    "            if not is_word_char(text1[i]) or not is_word_char(text2[j]):\n",
    "                dp[i][j] = 0 # reset outside each token\n",
    "\n",
    "            elif text1[i] == text2[j]:\n",
    "                dp[i][j] = 1 + dp[i+1][j+1] # (token-by-token) longest common subsequence\n",
    "\n",
    "                graph[(i,j)] = (i+1, j+1)\n",
    "\n",
    "                k = (root1[i], root2[j])\n",
    "\n",
    "                if k not in max_ij:\n",
    "                    max_ij[k] = [] # create if there is no key\n",
    "                while max_ij[k]: # pop the last element until its dp value is not smaller than that of the current dp\n",
    "                    a, b = max_ij[k][-1]\n",
    "                    if dp[a][b] < dp[i][j]: \n",
    "                        max_ij[k].pop()\n",
    "                    else:\n",
    "                        break\n",
    "                # max_ij[k].append((i, j)) # BUG! DON'T USE THIS LINE\n",
    "                if not max_ij[k] or dp[max_ij[k][-1][0]][max_ij[k][-1][1]] <= dp[i][j]:\n",
    "                    max_ij[k].append((i, j))\n",
    "\n",
    "            else:\n",
    "                dp[i][j] = max(dp[i+1][j], dp[i][j+1]) # (token-by-token) longest common subsequence\n",
    "\n",
    "                graph[(i,j)] = (i+1, j) if dp[i+1][j] >= dp[i][j+1] else (i, j+1) # if dp[i+1][j] == dp[i][j+1], then select (i+1, j), i.e. downward pointer\n",
    "\n",
    "    if verbose:\n",
    "        print('\\ndp = ')\n",
    "        print(f\"  [{', '.join(list(text2))}]\")\n",
    "        for c, d in zip(text1, dp): \n",
    "            print(c, d)\n",
    "\n",
    "    if verbose:\n",
    "        print('\\nmax_ij = ')\n",
    "        for k,v in max_ij.items(): \n",
    "            print(f'{k}: {v}')\n",
    "        print(f'\\ngraph = {graph}')\n",
    "\n",
    "\n",
    "    #--- select the very first match among one or many in each token-token pair [APPROXIMATION] ---------------------------------\n",
    "    m_ij = {}\n",
    "    for (ri,rj), vv in max_ij.items(): # (ri,rj) = root (i,j) \n",
    "        seen = set()\n",
    "        for k, (x, y) in enumerate(reversed(vv)):\n",
    "            match_only = []\n",
    "            while ((x,y) not in seen) and (dp[x][y] > 0):\n",
    "                if text1[x] == text2[y]:\n",
    "                    match_only.append((x,y))\n",
    "                seen.add((x,y))\n",
    "                x,y = graph[(x,y)] # next coordinate\n",
    "\n",
    "            a, b = match_only[-1]\n",
    "            if dp[a][b] == 1:\n",
    "                m_ij[(ri,rj,k)] = match_only\n",
    "\n",
    "    if verbose:\n",
    "        print('\\nm_ij = ')\n",
    "        for k,v in m_ij.items(): \n",
    "            print(f'{k}: {v}')\n",
    "\n",
    "\n",
    "    #--- prioritize all possible token matches by sorting with certain criteria (greedy method, which may not always give the best) [APPROXIMATION] ---------------\n",
    "    mm = []\n",
    "    for (ri, rj, k), vv in m_ij.items():\n",
    "        i, j = vv[0]\n",
    "        assert dp[i][j] == len(vv)\n",
    "        # mm.append((\n",
    "        #     ri, rj, k,\n",
    "        #     1*(text1[ri]==text2[rj]), # first character match\n",
    "        #     dp[i][j], # number of character matches\n",
    "        #     max(dp[i][j]/csum1[ri], dp[i][j]/csum2[rj]), # max ratio of matched characters in each token\n",
    "        #     ))\n",
    "        mm.append({\n",
    "            'ri': ri, \n",
    "            'rj': rj, \n",
    "            'k': k,\n",
    "            # 'is_first_match': 1*(text1[ri]==text2[rj]), # first character match\n",
    "            'is_first_match': (ri==i) + (rj==j), # first character match for each token pair\n",
    "            'n_matched': dp[i][j], # number of character matches\n",
    "            'max_ratio': max(dp[i][j]/csum1[ri], dp[i][j]/csum2[rj]), # max ratio of matched characters in each token\n",
    "            })\n",
    "    # mm.sort(key = lambda x: (-x[3], -x[4], -x[5], x[0], x[1], x[2])) # sorting criteria\n",
    "    mm.sort(key = lambda x: (-x['is_first_match'], -x['n_matched'], -x['max_ratio'], x['ri'], x['rj'], x['k'])) # sorting criteria\n",
    "\n",
    "    if verbose:\n",
    "        print('\\nmm = ')\n",
    "        for m in mm:\n",
    "            print(m)\n",
    "        print()\n",
    "\n",
    "    #--- assign the same group number for matched characters --------------------------------------\n",
    "    n_grp = 0 # group number\n",
    "    match1, chunk1 = [-1] * len(text1), [-1] * len(text1) # initialize all as unassigned (-1)\n",
    "    match2, chunk2 = [-1] * len(text2), [-1] * len(text2) # initialize all as unassigned (-1)\n",
    "    # for ri, rj, k, is_first_match, n_matched, max_ratio in mm: # try matching in this sorted order\n",
    "    for i_m, row in enumerate(mm): # try matching in this sorted order\n",
    "        ri, rj, k, is_first_match, n_matched, max_ratio = row['ri'], row['rj'], row['k'], row['is_first_match'], row['n_matched'], row['max_ratio']\n",
    "\n",
    "        if ((max_ratio == 1) # only if one token is inclusive of or equal to the other: i.e. max_ratio == 1\n",
    "            # and all(match1[i] < 0 and match2[j] < 0 for i, j in m_ij[(ri,rj,k)]) # if all the detected characters are still unassigned\n",
    "            and all(chunk1[i] < 0 and chunk2[j] < 0 for i, j in m_ij[(ri,rj,k)]) # if all the detected characters are still unassigned\n",
    "            ):\n",
    "            for nn, (i, j) in enumerate(m_ij[(ri,rj,k)]):\n",
    "                match1[i], match2[j] = n_grp, n_grp # assign the group number for the matched pairs\n",
    "\n",
    "                #--- find a countinuous chunk of matched characters, to prevent another matching between matched characters: e.g. AA___A__A B CCC (okay), AA_B_A__A _ CCC (not okay)\n",
    "                if nn == 0:\n",
    "                    i_prev, j_prev = i,  j\n",
    "                for ix in range(i_prev, i+1):\n",
    "                    chunk1[ix] = n_grp\n",
    "                for jx in range(j_prev, j+1):\n",
    "                    chunk2[jx] = n_grp\n",
    "                i_prev, j_prev = i,  j\n",
    "\n",
    "            mm[i_m]['group_num_assigned'] = n_grp # output for debuging purpose \n",
    "            \n",
    "            n_grp += 1 # change the group number for the next matched pair\n",
    "\n",
    "    #-------------------------------------------------------------------------\n",
    "    ii_remaining_1 = set(ii1.keys()).intersection([i for i, (t,m) in enumerate(zip(csum1, match1)) if t > 0 and m < 0]) # if token and not assigned\n",
    "    ii_remaining_2 = set(ii2.keys()).intersection([i for i, (t,m) in enumerate(zip(csum2, match2)) if t > 0 and m < 0]) # if token and not assigned\n",
    "\n",
    "    if verbose: print('\\nmatch1 =', match1)\n",
    "    if verbose: print('match2 =', match2)\n",
    "    if verbose: print('\\nii_remaining_1 =', ii_remaining_1, '; ii_remaining_2 =', ii_remaining_2)\n",
    "\n",
    "    #--- final decision ---------------------------------------------------\n",
    "    if version == '3':\n",
    "        is_same = len(ii_remaining_1) == 0 and len(ii_remaining_2) == 0\n",
    "    else:\n",
    "        cnt1 = count_consecutive_initials(ii1, ii_remaining_1)\n",
    "        cnt2 = count_consecutive_initials(ii2, ii_remaining_2)\n",
    "        if verbose: print('\\ncnt1 =', cnt1)\n",
    "        if verbose: print('cnt2 =', cnt2)\n",
    "        is_same = (\n",
    "            (len(ii_remaining_1) == 0 and (len(ii1) <= len(ii2) - len(ii_remaining_2))) or\n",
    "            (len(ii_remaining_2) == 0 and (len(ii2) <= len(ii1) - len(ii_remaining_1)))\n",
    "            ) and (cnt1 == 1 and cnt2 == 1)\n",
    "\n",
    "    if verbose:\n",
    "        match_out1 = f\"{text1}\\n{''.join(['^' if n >=0 else ' ' for n in match1])}\\n{''.join([chr(ord('A')+n) if n >=0 else ' ' for n in match1])}\"\n",
    "        match_out2 = f\"{text2}\\n{''.join(['^' if n >=0 else ' ' for n in match2])}\\n{''.join([chr(ord('A')+n) if n >=0 else ' ' for n in match2])}\"\n",
    "        print(match_out1)\n",
    "        print(match_out2)\n",
    "        print(match_out2)\n",
    "\n",
    "    return is_same, dp, mm, ii_remaining_1, ii_remaining_2, match1, match2, csum1, csum2, root1, root2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tom Park\n",
      "^^^ ^^^^\n",
      "BBB AAAA\n",
      "Tomas Park\n",
      "^^^   ^^^^\n",
      "BBB   AAAA\n",
      "-----------------------------------------------------------\n",
      "Bomsoo Kim\n",
      "^^^^^^ ^^^\n",
      "AAACCC BBB\n",
      "Bom Soo Kim\n",
      "^^^ ^^^ ^^^\n",
      "AAA CCC BBB\n",
      "-----------------------------------------------------------\n",
      "Bomsoo Kim\n",
      "^^^^^^ ^^^\n",
      "AAACCC BBB\n",
      "Kim Bom Soo\n",
      "^^^ ^^^ ^^^\n",
      "BBB AAA CCC\n",
      "-----------------------------------------------------------\n",
      "Brad Kim\n",
      "     ^^^\n",
      "     AAA\n",
      "Bomsoo Kim\n",
      "       ^^^\n",
      "       AAA\n",
      "-----------------------------------------------------------\n",
      "Bomsoo Brad Kim\n",
      "^^^^^^ ^    ^^^\n",
      "AAAAAA C    BBB\n",
      "Bomsoo B. Kim\n",
      "^^^^^^ ^  ^^^\n",
      "AAAAAA C  BBB\n",
      "-----------------------------------------------------------\n",
      "Bank of United States of America\n",
      "^^^^ ^^ ^      ^         ^      \n",
      "AAAA BB C      D         E      \n",
      "Bank of U.S.A.\n",
      "^^^^ ^^ ^ ^ ^ \n",
      "AAAA BB C D E \n",
      "-----------------------------------------------------------\n",
      "Finexus Limited.\n",
      "^^^^^^^ ^   ^ ^ \n",
      "BBCCCCC A   A A \n",
      "Fi-nexus ltd\n",
      "^^ ^^^^^ ^^^\n",
      "BB CCCCC AAA\n",
      "-----------------------------------------------------------\n",
      "Finexus co. Limited.\n",
      "^^^^^^^ ^^  ^   ^ ^ \n",
      "BBDDDDD CC  A   A A \n",
      "Fi-nexus Corporation ltd\n",
      "^^ ^^^^^ ^^          ^^^\n",
      "BB DDDDD CC          AAA\n",
      "-----------------------------------------------------------\n",
      "International Inn Corporation. Ltd\n",
      "^             ^   ^^           ^^^\n",
      "C             D   BB           AAA\n",
      "I. I. Co. Limited\n",
      "^  ^  ^^  ^   ^ ^\n",
      "C  D  BB  A   A A\n",
      "-----------------------------------------------------------\n",
      "International I. Corporation. Ltd\n",
      "^^   ^        ^  ^^           ^^^\n",
      "AA   A        D  CC           BBB\n",
      "I. Inn Co. Limited\n",
      "^  ^^^ ^^  ^   ^ ^\n",
      "D  AAA CC  B   B B\n",
      "-----------------------------------------------------------\n",
      "International I. Corporation. Ltd\n",
      "^^^           ^  ^^           ^^^\n",
      "AAA           D  CC           BBB\n",
      "Int. Inn Co. Limited\n",
      "^^^  ^   ^^  ^   ^ ^\n",
      "AAA  D   CC  B   B B\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    import re\n",
    "    import pandas as pd\n",
    "\n",
    "    data = []\n",
    "    for text1, text2, true_answer in [\n",
    "        ('Tom Park', 'Tomas Park', True),\n",
    "        ('Bomsoo Kim', 'Bom Soo Kim', True),\n",
    "        ('Bomsoo Kim', 'Kim Bom Soo', True),\n",
    "        ('Brad Kim', 'Bomsoo Kim', False),\n",
    "        ('Bomsoo Brad Kim', 'Bomsoo B. Kim', True),\n",
    "        ('Bank of United States of America', 'Bank of U.S.A.', True),\n",
    "        ('Finexus Limited.', 'Fi-nexus ltd', True),\n",
    "        ('Finexus co. Limited.', 'Fi-nexus Corporation ltd', True),\n",
    "        ('International Inn Corporation. Ltd', 'I. I. Co. Limited', True),\n",
    "        ('International I. Corporation. Ltd', 'I. Inn Co. Limited', True),\n",
    "        ('International I. Corporation. Ltd', 'Int. Inn Co. Limited', True),\n",
    "        # ('abc', 'abcabc', True),\n",
    "        # ('abc abc', 'abcabc', True),\n",
    "        # ('abc', 'aabbcc', True),\n",
    "        # ('abc abc', 'aabbcc', False),\n",
    "        # ('abc', 'aaaaaabc', True),\n",
    "        # ('xab', 'axb', False),\n",
    "        # ('axbc', 'abcx', False),\n",
    "        # ('abc abc', 'abcabcxa', True),\n",
    "        # ('aecxef ghi', 'aec xef ghi', True),\n",
    "        ]:\n",
    "        ver1 =  compare_text(text1.lower(), text2.lower(), version='1')\n",
    "        ver2 =  compare_text(text1.lower(), text2.lower(), version='2')\n",
    "        ver3, dp, mm, ii_remaining_1, ii_remaining_2, match1, match2, csum1, csum2, root1, root2 = compare_text(text1.lower(), text2.lower(), version='3')\n",
    "        latest, dp, mm, ii_remaining_1, ii_remaining_2, match1, match2, csum1, csum2, root1, root2 = compare_text(text1.lower(), text2.lower(), verbose=False)\n",
    "        # latest, dp, mm, ii_remaining_1, ii_remaining_2, match1, match2, csum1, csum2, root1, root2 = compare_text(text1.lower(), text2.lower(), verbose=True)\n",
    "\n",
    "        match_out1 = f\"{text1}\\n{''.join(['^' if n >=0 else ' ' for n in match1])}\\n{''.join([chr(ord('A')+n) if n >=0 else ' ' for n in match1])}\"\n",
    "        match_out2 = f\"{text2}\\n{''.join(['^' if n >=0 else ' ' for n in match2])}\\n{''.join([chr(ord('A')+n) if n >=0 else ' ' for n in match2])}\"\n",
    "\n",
    "        data.append({'text1':text1, 'text2':text2, 'true_answer':true_answer, 'ver1':ver1, 'ver2':ver2, 'ver3':ver3, 'ver3.1':latest, 'ver2 or ver3':ver2 or ver3, 'ver2 or ver3.1':ver2 or latest, 'match_out':f'{match_out1}\\n{match_out2}'})\n",
    "\n",
    "        print(match_out1)\n",
    "        print(match_out2)\n",
    "        print('-----------------------------------------------------------')\n",
    "\n",
    "    # df = pd.DataFrame(data)\n",
    "    # df.to_excel('name_matching.xlsx')\n",
    "    # df\n",
    "\n",
    "    # with open('log.txt', 'a') as f:\n",
    "    #     f.write(text1 + '\\n')\n",
    "    #     f.write(s1 + '\\n')\n",
    "    #     f.write(text2 + '\\n')\n",
    "    #     f.write(s2 + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
